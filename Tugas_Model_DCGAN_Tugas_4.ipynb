{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHsoqdYgxMCF5aPGWnRXdG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sriayuningsih02/Deep-Learning-Lanjut/blob/main/Tugas_Model_DCGAN_Tugas_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUBFuYtcC2d0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Konfigurasi agar GPU digunakan secara efisien\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    print(\"GPU Terdeteksi: \", physical_devices[0])\n",
        "else:\n",
        "    print(\"Peringatan: GPU tidak terdeteksi. Training akan lambat.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the .kaggle directory if it doesn't exist\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Move the kaggle.json file to the .kaggle directory\n",
        "# IMPORTANT: Make sure you have uploaded kaggle.json to your Colab session's /content/ directory first.\n",
        "# If you uploaded it somewhere else, adjust the source path accordingly.\n",
        "!mv /content/kaggle.json ~/.kaggle/\n",
        "\n",
        "# Set read-only permissions for the kaggle.json file for security\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"Kaggle API credentials set up successfully!\")"
      ],
      "metadata": {
        "id": "reQuES8MDMIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install kaggle if not already installed\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Make sure your Kaggle API credentials (kaggle.json) are set up in ~/.kaggle/\n",
        "# If you haven't done this, please refer to the previous instructions.\n",
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d joosthazelzet/lego-brick-images\n",
        "\n",
        "# Unzip the downloaded dataset to the specified directory\n",
        "# The zip file will be downloaded to the current working directory (/content/)\n",
        "!unzip -q /content/lego-brick-images.zip -d /content/dataset/\n",
        "\n",
        "# Clean up the zip file after extraction\n",
        "!rm /content/lego-brick-images.zip\n",
        "\n",
        "print(\"Dataset downloaded and extracted to /content/dataset/\")"
      ],
      "metadata": {
        "id": "gGBPv6vtDMAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter Konfigurasi\n",
        "BATCH_SIZE = 64\n",
        "IMG_HEIGHT = 64  # Menggunakan 64x64 agar detail LEGO cukup terlihat\n",
        "IMG_WIDTH = 64\n",
        "CHANNELS = 3     # RGB\n",
        "\n",
        "\n",
        "# --- OPSI B: Membuat Dataset Loader ---\n",
        "# Ganti 'path/to/images' dengan path folder dataset Anda\n",
        "dataset_dir = '/content/dataset/LEGO brick images v1'\n",
        "\n",
        "# Jika folder kosong/tidak ada, kita buat dummy data agar kode tetap jalan (untuk testing)\n",
        "if not os.path.exists(dataset_dir) or not os.listdir(dataset_dir):\n",
        "    print(\"Dataset tidak ditemukan. Membuat data dummy untuk demonstrasi struktur kode.\")\n",
        "    os.makedirs(dataset_dir, exist_ok=True)\n",
        "    # Membuat 100 gambar random noise sebagai placeholder\n",
        "    for i in range(100):\n",
        "        img = np.random.randint(0, 255, (64, 64, 3), dtype=np.uint8)\n",
        "        tf.keras.utils.save_img(f\"{dataset_dir}/dummy_{i}.png\", img)\n",
        "\n",
        "# Memuat dataset\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_dir,\n",
        "    label_mode=None, # Kita tidak butuh label untuk GAN\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Normalisasi ke [-1, 1]\n",
        "train_dataset = train_dataset.map(lambda x: (x - 127.5) / 127.5)\n",
        "\n",
        "# Optimasi performa (Caching & Prefetching)\n",
        "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "okjJFfR7DL7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 128\n",
        "\n",
        "def build_generator():\n",
        "    model = keras.Sequential(name=\"generator\")\n",
        "\n",
        "    # Input: Latent Vector\n",
        "    # Mulai dengan dense layer yang cukup besar untuk di-reshape\n",
        "    # Kita ingin mulai dari ukuran 8x8 dengan 512 filter\n",
        "    model.add(layers.Dense(8 * 8 * 512, use_bias=False, input_shape=(latent_dim,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Reshape menjadi tensor 3D\n",
        "    model.add(layers.Reshape((8, 8, 512)))\n",
        "\n",
        "    # Upsampling 1: 8x8 -> 16x16\n",
        "    model.add(layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Upsampling 2: 16x16 -> 32x32\n",
        "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Upsampling 3: 32x32 -> 64x64\n",
        "    model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Output Layer: 64x64 -> 64x64x3 (RGB)\n",
        "    # Aktivasi TANH penting agar output di range [-1, 1]\n",
        "    model.add(layers.Conv2D(CHANNELS, (3, 3), padding='same', activation='tanh'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def build_discriminator():\n",
        "    model = keras.Sequential(name=\"discriminator\")\n",
        "\n",
        "    # Input: Gambar 64x64x3\n",
        "    # Downsampling 1: 64 -> 32\n",
        "    model.add(layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS)))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    # Downsampling 2: 32 -> 16\n",
        "    model.add(layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    # Downsampling 3: 16 -> 8\n",
        "    model.add(layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    # Flatten dan Output\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1)) # Output berupa logit (skor real/fake)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Inisialisasi Model\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "generator.summary()\n",
        "# discriminator.summary()"
      ],
      "metadata": {
        "id": "l0I_ghubDL2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DCGAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(DCGAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(DCGAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        # Metric trackers\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # 1. Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # 2. Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # 3. Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # 4. Assemble labels discriminating real from fake images\n",
        "        # Label 1 untuk fake, 0 untuk real (atau sebaliknya, teknik ini menggunakan label smoothing)\n",
        "        # Di sini kita pakai standar: 1=Real, 0=Fake.\n",
        "        # Namun, karena kita concat [Fake, Real], maka labelnya: [0...0, 1...1]\n",
        "        labels = tf.concat(\n",
        "            [tf.zeros((batch_size, 1)), tf.ones((batch_size, 1))], axis=0\n",
        "        )\n",
        "\n",
        "        # Tambahkan sedikit noise pada label (Label Smoothing) untuk stabilitas\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # 5. Train the Discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # 6. Sample random points in the latent space (lagi, untuk Generator)\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # 7. Assemble labels that say \"all real images\" (We want to fool the discriminator)\n",
        "        misleading_labels = tf.ones((batch_size, 1))\n",
        "\n",
        "        # 8. Train the Generator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(\n",
        "            zip(grads, self.generator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "nB60MBCFDLyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 127.5\n",
        "        generated_images += 127.5\n",
        "        generated_images.numpy()\n",
        "\n",
        "        fig = plt.figure(figsize=(10, 4))\n",
        "        for i in range(self.num_img):\n",
        "            plt.subplot(1, self.num_img, i+1)\n",
        "            img = keras.utils.array_to_img(generated_images[i])\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.suptitle(f\"Epoch {epoch+1}\")\n",
        "        plt.show() # Tampilkan inline di Colab\n",
        "\n",
        "        # Opsional: Simpan ke file\n",
        "        # plt.savefig(f\"generated_lego_epoch_{epoch}.png\")\n",
        "        # plt.close()"
      ],
      "metadata": {
        "id": "52lKdoidDLtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "EPOCHS = 500  # Tambahkan jumlah epoch untuk hasil lebih baik (misal: 100-200)\n",
        "lr_generator = 0.0002\n",
        "lr_discriminator = 0.0002\n",
        "\n",
        "# Inisialisasi DCGAN\n",
        "dcgan = DCGAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "\n",
        "# Compile\n",
        "dcgan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=lr_discriminator, beta_1=0.5),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=lr_generator, beta_1=0.5),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        ")\n",
        "\n",
        "# Jalankan Training\n",
        "print(\"Mulai Training...\")\n",
        "dcgan.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[GANMonitor(num_img=3, latent_dim=latent_dim)]\n",
        ")"
      ],
      "metadata": {
        "id": "xIenD2t1DLnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.save('generator_model.keras')\n",
        "print(\"Generator model saved as 'generator_model.keras'\")"
      ],
      "metadata": {
        "id": "dlsAEg92DLkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_generated_images = 5\n",
        "random_latent_vectors = tf.random.normal(shape=(num_generated_images, latent_dim))\n",
        "\n",
        "generated_images = generator(random_latent_vectors)\n",
        "generated_images = (generated_images * 127.5) + 127.5 # Denormalize to [0, 255]\n",
        "generated_images = tf.cast(generated_images, tf.uint8)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(num_generated_images):\n",
        "    plt.subplot(1, num_generated_images, i + 1)\n",
        "    plt.imshow(generated_images[i].numpy())\n",
        "    plt.axis('off')\n",
        "plt.suptitle(\"Generated Images\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e7woBTUxDLgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_interpolation_steps = 5\n",
        "\n",
        "# Generate two random latent vectors\n",
        "start_latent_vector = tf.random.normal(shape=(1, latent_dim))\n",
        "end_latent_vector = tf.random.normal(shape=(1, latent_dim))\n",
        "\n",
        "# Perform linear interpolation in latent space\n",
        "interpolated_latent_vectors = []\n",
        "for i in range(num_interpolation_steps):\n",
        "    alpha = i / (num_interpolation_steps - 1)\n",
        "    interpolated_vector = (1 - alpha) * start_latent_vector + alpha * end_latent_vector\n",
        "    interpolated_latent_vectors.append(interpolated_vector)\n",
        "\n",
        "interpolated_latent_vectors = tf.concat(interpolated_latent_vectors, axis=0)\n",
        "\n",
        "# Generate images from the interpolated latent vectors\n",
        "generated_images_interp = generator(interpolated_latent_vectors)\n",
        "generated_images_interp = (generated_images_interp * 127.5) + 127.5 # Denormalize to [0, 255]\n",
        "generated_images_interp = tf.cast(generated_images_interp, tf.uint8)\n",
        "\n",
        "# Display the interpolated images\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i in range(num_interpolation_steps):\n",
        "    plt.subplot(1, num_interpolation_steps, i + 1)\n",
        "    plt.imshow(generated_images_interp[i].numpy())\n",
        "    plt.axis('off')\n",
        "plt.suptitle(\"Generated Images (Latent Space Interpolation)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nH-RM9WJDLc7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}